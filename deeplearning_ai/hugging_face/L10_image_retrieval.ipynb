{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29ef44f6-876d-4c92-bfa2-885dac873ad9",
   "metadata": {},
   "source": [
    "# Lesson 10: Image Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa61c20e",
   "metadata": {},
   "source": [
    "- In the classroom, the libraries are already installed for you.\n",
    "- If you would like to run this code on your own machine, you can install the following:\n",
    "\n",
    "```\n",
    "    !pip install transformers\n",
    "    !pip install torch\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190858c7-792d-4695-ba6d-b502c1d25b03",
   "metadata": {},
   "source": [
    "- Here is some code that suppresses warning messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1faec1a-dcda-4b44-84b8-1631f0bb464e",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "from transformers import AutoProcessor, BlipForImageTextRetrieval\n",
    "from transformers.utils import logging\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847fac54",
   "metadata": {},
   "source": [
    "- Load the model and the processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417991ee-dbf7-48fe-83a6-b6d5700632be",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "model = BlipForImageTextRetrieval.from_pretrained(\n",
    "    \"./models/Salesforce/blip-itm-base-coco\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80ab891",
   "metadata": {},
   "source": [
    "More info about [Salesforce/blip-itm-base-coco](https://huggingface.co/Salesforce/blip-itm-base-coco)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50faf354-91e4-4739-8e2d-7547504e4c92",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(\n",
    "    \"./models/Salesforce/blip-itm-base-coco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e72f24c-86b8-48d3-af80-07434ea43522",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "img_url = (\n",
    "    'https://storage.googleapis.com/sfr-vision-language-research/BLIP/'\n",
    "    'demo.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d711df0-1f01-42e5-b397-8ffcb6ef4c12",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "raw_image =  Image.open(\n",
    "    requests.get(img_url, stream=True).raw\n",
    ").convert('RGB')\n",
    "raw_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38db1166-f8c1-4f06-ad67-7083492b6ceb",
   "metadata": {},
   "source": [
    "### Test, if the image matches the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edee591-c891-4b4b-91ee-1e9f54642e97",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "text = \"an image of a woman and a dog on the beach\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b41ec7-70d7-49c2-909a-e600ab7e76ca",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "inputs = processor(images=raw_image, text=text, return_tensors=\"pt\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db51ff2e-74c2-4ea1-b271-48d8f15e7fd6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "itm_scores = model(**inputs)[0]\n",
    "itm_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0a433f-d1f1-45c7-b776-1472b8a7cbcd",
   "metadata": {},
   "source": [
    "- Use a softmax layer to get the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0749cbf-be41-4b47-92ac-a0f6515ff31e",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "itm_score = torch.nn.functional.softmax(itm_scores, dim=1)\n",
    "itm_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f000eb6-2b6a-48c5-8481-a3bbdd5b3c5d",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f'The image and text match with a probability of '\n",
    "    f'{itm_score[0][1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416bc237",
   "metadata": {},
   "source": [
    "### Try it yourself! \n",
    "- Try this model with your own images and texts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02012ee6-68f8-4b18-ba64-9596cdcd9f9d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
